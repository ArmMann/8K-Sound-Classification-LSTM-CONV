{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "MEdUkmcwENu0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrZfBJtGYd_"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky4oTb5hGOaQ",
        "outputId": "dcae7555-abf6-495e-c4d7-db27ab0c9980"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the UrbanSound8K dataset\n",
        "dataset = load_dataset(\"danavery/urbansound8K\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o8pUbfaHsMm",
        "outputId": "fec40ab2-5f13-4880-8e07-0fe28e3a368a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'slice_file_name', 'fsID', 'start', 'end', 'salience', 'fold', 'classID', 'class'],\n",
              "        num_rows: 8732\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Ajub8hObJH",
        "outputId": "d03c3365-b275-44a9-ce34-c5d7c597e2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'path': '100032-3-0-0.wav', 'array': array([-0.00454712, -0.00483704, -0.00460815, ..., -0.00065613,\n",
            "       -0.00048828,  0.        ]), 'sampling_rate': 44100}\n"
          ]
        }
      ],
      "source": [
        "first_item = dataset['train'][0]\n",
        "print(first_item['audio'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqqEJXT6Hsyh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oDEBbatoGcfE"
      },
      "outputs": [],
      "source": [
        "def preprocess_audio(batch):\n",
        "    # Parameters for spectrogram\n",
        "    n_mels = 64\n",
        "    n_fft = 1024\n",
        "    win_length = None\n",
        "    hop_length = 512\n",
        "    sample_rate = 44100\n",
        "\n",
        "    # Transformation pipeline for spectrogram\n",
        "    transformation = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=n_fft,\n",
        "        win_length=win_length,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "\n",
        "    for audio_data, label in zip(batch['audio'], batch['classID']):\n",
        "        # Extract waveform from 'audio' dictionary\n",
        "        waveform = torch.from_numpy(audio_data['array']).float()\n",
        "\n",
        "        # Resampling (if needed)\n",
        "        if audio_data['sampling_rate'] != sample_rate:\n",
        "            resampler = T.Resample(orig_freq=audio_data['sampling_rate'], new_freq=sample_rate)\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "        # Ensure waveform is 1D\n",
        "        if waveform.ndim > 1:\n",
        "            waveform = waveform.mean(dim=0)\n",
        "\n",
        "        # Apply transformation\n",
        "        spectrogram = transformation(waveform).squeeze(0)\n",
        "\n",
        "        # Normalization\n",
        "        spectrogram = (spectrogram - spectrogram.mean()) / spectrogram.std()\n",
        "\n",
        "        spectrogram = spectrogram.unsqueeze(0)  # Add channel dimension\n",
        "        spectrograms.append(spectrogram)\n",
        "        labels.append(label)\n",
        "\n",
        "    max_length = max([spec.shape[-1] for spec in spectrograms])\n",
        "    # Pad each spectrogram to this maximum size and store in a new list\n",
        "    padded_spectrograms = [torch.nn.functional.pad(spec, (0, max_length - spec.shape[-1])) for spec in spectrograms]\n",
        "\n",
        "    # Now we can stack the padded spectrograms\n",
        "    spectrograms_tensor = torch.stack(padded_spectrograms)\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return {'spectrogram': spectrograms_tensor, 'label': labels_tensor}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gvXgRVvcOqeB"
      },
      "outputs": [],
      "source": [
        "#Here we also take global max length over batches\n",
        "def data_generator(dataset, batch_size=32):\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        batch = dataset[i:i + batch_size]\n",
        "        preprocessed_batch = preprocess_audio(batch)\n",
        "        lengths = [spec.shape[-1] for spec in preprocessed_batch['spectrogram']]\n",
        "        yield preprocessed_batch, [int(length) for length in lengths]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lQzYvT3TT8l",
        "outputId": "4a59ed29-b874-4bc6-968c-d07547635c1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'slice_file_name', 'fsID', 'start', 'end', 'salience', 'fold', 'classID', 'class'],\n",
              "        num_rows: 8732\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yEcL4j4FNu-h"
      },
      "outputs": [],
      "source": [
        "max_length = 0\n",
        "accumulated_data = []\n",
        "lengths = []\n",
        "\n",
        "for preprocessed_chunk, chunk_lengths in data_generator(dataset['train']):\n",
        "    accumulated_data.append(preprocessed_chunk)\n",
        "    lengths.extend(chunk_lengths)\n",
        "    max_length = max(max_length, max(chunk_lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkOnL0ZYaQc-",
        "outputId": "3b538dfd-5343-4d33-88c3-7c95e153310e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "348"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2eIH1D0TFD_",
        "outputId": "66b3c212-6dd5-48f6-9964-a32ad598da41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "273"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(accumulated_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggGzFnG_TNMD",
        "outputId": "26b7aec5-4928-4f0e-f7c9-d960144e8282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8736"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "32*273"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wj9ifLAMTSSZ"
      },
      "outputs": [],
      "source": [
        "# Function to pad spectrograms\n",
        "def pad_spectrogram(spec, max_len):\n",
        "    return torch.nn.functional.pad(spec, (0, max_len - spec.shape[-1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKcPVhO-TaJx"
      },
      "source": [
        "Turning 273 batches of our data into Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vjo5xWbAPGNz"
      },
      "outputs": [],
      "source": [
        "# Padding and concatenating\n",
        "all_spectrograms = torch.cat([pad_spectrogram(data['spectrogram'], max_length) for data in accumulated_data])\n",
        "all_labels = torch.cat([data['label'] for data in accumulated_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PPaAsTcjPZno"
      },
      "outputs": [],
      "source": [
        "final_dataset = {'spectrogram': all_spectrograms, 'label': all_labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWbV1ez6J-mn"
      },
      "source": [
        "# Spliting and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xzzNrSKVKBVu"
      },
      "outputs": [],
      "source": [
        "#  final_dataset to TensorDataset\n",
        "dataset = TensorDataset(final_dataset['spectrogram'], final_dataset['label'])\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NgYonpk9KB7m"
      },
      "outputs": [],
      "source": [
        "# DataLoaders for Train and Test \n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwvQGv9IKGTV",
        "outputId": "03193864-547f-439a-8ee0-17f087054334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of spectrograms: torch.Size([32, 1, 64, 348])\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "spectrograms, labels = next(dataiter)\n",
        "print(\"Shape of spectrograms:\", spectrograms.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAY6bTwkKKhq"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GOfRg5IZKMA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AudioClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AudioClassifier, self).__init__()\n",
        "\n",
        "        # configurations\n",
        "        conv_filters = [32, 64, 128, 256, 512, 512]\n",
        "        kernel_size = 3\n",
        "        pool_size = 2\n",
        "        dropout_rates = [0.25, 0.3, 0.4, 0.5, 0.5, 0.5]\n",
        "        dense_units = 128\n",
        "        lstm_units = 128\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "\n",
        "        in_channels = 1\n",
        "        for i, out_channels in enumerate(conv_filters):\n",
        "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding='same'))\n",
        "            self.batch_norms.append(nn.BatchNorm2d(out_channels))\n",
        "            self.dropouts.append(nn.Dropout(dropout_rates[i]))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=pool_size)\n",
        "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size=conv_filters[-1], hidden_size=lstm_units, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(input_size=lstm_units * 2, hidden_size=lstm_units, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.dense1 = nn.Linear(lstm_units * 2, dense_units)\n",
        "        self.dense2 = nn.Linear(dense_units, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass \n",
        "        #print(\"Shape before CONV layers:\", x.shape)\n",
        "        for conv, bn, dropout in zip(self.conv_layers, self.batch_norms, self.dropouts):\n",
        "            x = self.pool(F.relu(bn(conv(x))))\n",
        "            x = dropout(x)\n",
        "\n",
        "        #print(\"Shape before Max Pooling:\", x.shape)\n",
        "        # Global Max Pooling and LSTM \n",
        "        x = self.gmp(x).squeeze(-1).squeeze(-1)  # Shape: [batch_size, channels]\n",
        "        #print(\"Shape after Max Pooling:\", x.shape)\n",
        "        x = x.unsqueeze(1)  # Shape: [batch_size,  1, channels] for LSTM\n",
        "        #print(\"Shape after unsqueezing 2nd dimension Pooling, i. e before lstm:\", x.shape)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        # Select the last time step's output for classification\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.dense1(x))\n",
        "        x = self.dense2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By6wrDJ4b0G5"
      },
      "source": [
        "# Training arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zK4wBto5LaNr"
      },
      "outputs": [],
      "source": [
        "num_classes = len(set(final_dataset['label'].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm1T09-Rb7ig",
        "outputId": "3a3b323c-6bdd-4e5f-abf1-3c276425e3f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mPfhY3ncKN2f"
      },
      "outputs": [],
      "source": [
        "model = AudioClassifier(num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ync1C_vmKRAC"
      },
      "outputs": [],
      "source": [
        "def train_and_save_checkpoint(model, criterion, optimizer, train_loader, test_loader, epochs=10, checkpoint_dir='checkpoints'):\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    model.lstm1.flatten_parameters()\n",
        "    model.lstm2.flatten_parameters()\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Move data to the same device as the model\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch+1}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "        # Evaluate on test \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for data in test_loader:\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            test_accuracy = 100 * correct / total\n",
        "            print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "        #  checkpoint every 5th epoch\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': train_loss,\n",
        "            }, checkpoint_path)\n",
        "            print(f'Checkpoint saved: {checkpoint_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DR3k2E5Ej20k"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDI7XJAML1yL",
        "outputId": "19c890a8-e3be-41d0-dd8f-bbb9b9adcb1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6239, Accuracy: 79.89%\n",
            "Test Accuracy: 81.91%\n",
            "Epoch 2, Loss: 0.6088, Accuracy: 79.93%\n",
            "Test Accuracy: 77.73%\n",
            "Epoch 3, Loss: 0.5499, Accuracy: 82.16%\n",
            "Test Accuracy: 81.97%\n",
            "Epoch 4, Loss: 0.5499, Accuracy: 82.39%\n",
            "Test Accuracy: 80.42%\n",
            "Epoch 5, Loss: 0.5204, Accuracy: 83.32%\n",
            "Test Accuracy: 80.37%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_5.pth\n",
            "Epoch 6, Loss: 0.5007, Accuracy: 83.87%\n",
            "Test Accuracy: 83.74%\n",
            "Epoch 7, Loss: 0.4851, Accuracy: 84.12%\n",
            "Test Accuracy: 84.66%\n",
            "Epoch 8, Loss: 0.4538, Accuracy: 85.08%\n",
            "Test Accuracy: 84.89%\n",
            "Epoch 9, Loss: 0.4435, Accuracy: 86.18%\n",
            "Test Accuracy: 84.37%\n",
            "Epoch 10, Loss: 0.4134, Accuracy: 86.74%\n",
            "Test Accuracy: 83.97%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_10.pth\n",
            "Epoch 11, Loss: 0.4162, Accuracy: 86.44%\n",
            "Test Accuracy: 85.86%\n",
            "Epoch 12, Loss: 0.4007, Accuracy: 86.70%\n",
            "Test Accuracy: 85.46%\n",
            "Epoch 13, Loss: 0.3878, Accuracy: 87.32%\n",
            "Test Accuracy: 87.41%\n",
            "Epoch 14, Loss: 0.3805, Accuracy: 87.69%\n",
            "Test Accuracy: 82.20%\n",
            "Epoch 15, Loss: 0.3531, Accuracy: 88.29%\n",
            "Test Accuracy: 88.72%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_15.pth\n",
            "Epoch 16, Loss: 0.3408, Accuracy: 88.79%\n",
            "Test Accuracy: 88.90%\n",
            "Epoch 17, Loss: 0.3488, Accuracy: 88.40%\n",
            "Test Accuracy: 88.55%\n",
            "Epoch 18, Loss: 0.3363, Accuracy: 88.89%\n",
            "Test Accuracy: 87.35%\n",
            "Epoch 19, Loss: 0.3104, Accuracy: 89.56%\n",
            "Test Accuracy: 85.75%\n",
            "Epoch 20, Loss: 0.3296, Accuracy: 89.35%\n",
            "Test Accuracy: 89.41%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_20.pth\n",
            "Epoch 21, Loss: 0.2957, Accuracy: 90.39%\n",
            "Test Accuracy: 88.38%\n",
            "Epoch 22, Loss: 0.2901, Accuracy: 90.48%\n",
            "Test Accuracy: 91.47%\n",
            "Epoch 23, Loss: 0.2834, Accuracy: 90.95%\n",
            "Test Accuracy: 88.04%\n",
            "Epoch 24, Loss: 0.2703, Accuracy: 90.71%\n",
            "Test Accuracy: 90.15%\n",
            "Epoch 25, Loss: 0.2709, Accuracy: 91.01%\n",
            "Test Accuracy: 87.75%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_25.pth\n",
            "Epoch 26, Loss: 0.2819, Accuracy: 91.05%\n",
            "Test Accuracy: 88.09%\n",
            "Epoch 27, Loss: 0.2504, Accuracy: 91.98%\n",
            "Test Accuracy: 91.87%\n",
            "Epoch 28, Loss: 0.2609, Accuracy: 91.47%\n",
            "Test Accuracy: 91.64%\n",
            "Epoch 29, Loss: 0.2527, Accuracy: 91.90%\n",
            "Test Accuracy: 86.66%\n",
            "Epoch 30, Loss: 0.2476, Accuracy: 91.81%\n",
            "Test Accuracy: 91.53%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_30.pth\n",
            "Epoch 31, Loss: 0.2540, Accuracy: 91.70%\n",
            "Test Accuracy: 89.93%\n",
            "Epoch 32, Loss: 0.2213, Accuracy: 92.83%\n",
            "Test Accuracy: 90.73%\n",
            "Epoch 33, Loss: 0.2317, Accuracy: 92.34%\n",
            "Test Accuracy: 90.96%\n",
            "Epoch 34, Loss: 0.2092, Accuracy: 93.01%\n",
            "Test Accuracy: 91.59%\n",
            "Epoch 35, Loss: 0.2070, Accuracy: 93.30%\n",
            "Test Accuracy: 90.96%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_35.pth\n",
            "Epoch 36, Loss: 0.2005, Accuracy: 93.30%\n",
            "Test Accuracy: 91.53%\n",
            "Epoch 37, Loss: 0.2057, Accuracy: 92.87%\n",
            "Test Accuracy: 92.44%\n",
            "Epoch 38, Loss: 0.1868, Accuracy: 93.89%\n",
            "Test Accuracy: 90.84%\n",
            "Epoch 39, Loss: 0.1897, Accuracy: 93.99%\n",
            "Test Accuracy: 90.73%\n",
            "Epoch 40, Loss: 0.1879, Accuracy: 93.86%\n",
            "Test Accuracy: 91.18%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_40.pth\n",
            "Epoch 41, Loss: 0.1918, Accuracy: 93.72%\n",
            "Test Accuracy: 91.70%\n",
            "Epoch 42, Loss: 0.1847, Accuracy: 93.86%\n",
            "Test Accuracy: 92.39%\n",
            "Epoch 43, Loss: 0.1870, Accuracy: 93.96%\n",
            "Test Accuracy: 90.50%\n",
            "Epoch 44, Loss: 0.1595, Accuracy: 94.62%\n",
            "Test Accuracy: 90.90%\n",
            "Epoch 45, Loss: 0.1782, Accuracy: 93.87%\n",
            "Test Accuracy: 91.59%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_45.pth\n",
            "Epoch 46, Loss: 0.1693, Accuracy: 94.49%\n",
            "Test Accuracy: 91.53%\n",
            "Epoch 47, Loss: 0.1677, Accuracy: 94.30%\n",
            "Test Accuracy: 91.93%\n",
            "Epoch 48, Loss: 0.1587, Accuracy: 94.47%\n",
            "Test Accuracy: 90.33%\n",
            "Epoch 49, Loss: 0.1553, Accuracy: 94.77%\n",
            "Test Accuracy: 92.50%\n",
            "Epoch 50, Loss: 0.1591, Accuracy: 95.00%\n",
            "Test Accuracy: 91.81%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_50.pth\n",
            "Epoch 51, Loss: 0.1504, Accuracy: 94.99%\n",
            "Test Accuracy: 92.04%\n",
            "Epoch 52, Loss: 0.1456, Accuracy: 95.35%\n",
            "Test Accuracy: 92.84%\n",
            "Epoch 53, Loss: 0.1537, Accuracy: 94.89%\n",
            "Test Accuracy: 90.38%\n",
            "Epoch 54, Loss: 0.1480, Accuracy: 95.23%\n",
            "Test Accuracy: 91.36%\n",
            "Epoch 55, Loss: 0.1279, Accuracy: 95.60%\n",
            "Test Accuracy: 92.96%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_55.pth\n",
            "Epoch 56, Loss: 0.1265, Accuracy: 95.73%\n",
            "Test Accuracy: 89.52%\n",
            "Epoch 57, Loss: 0.1536, Accuracy: 94.62%\n",
            "Test Accuracy: 92.04%\n",
            "Epoch 58, Loss: 0.1397, Accuracy: 95.63%\n",
            "Test Accuracy: 90.90%\n",
            "Epoch 59, Loss: 0.1417, Accuracy: 95.40%\n",
            "Test Accuracy: 88.21%\n",
            "Epoch 60, Loss: 0.1252, Accuracy: 95.66%\n",
            "Test Accuracy: 92.33%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_60.pth\n",
            "Epoch 61, Loss: 0.1179, Accuracy: 96.29%\n",
            "Test Accuracy: 90.44%\n",
            "Epoch 62, Loss: 0.1262, Accuracy: 95.66%\n",
            "Test Accuracy: 92.16%\n",
            "Epoch 63, Loss: 0.1391, Accuracy: 95.48%\n",
            "Test Accuracy: 89.52%\n",
            "Epoch 64, Loss: 0.1533, Accuracy: 94.99%\n",
            "Test Accuracy: 93.07%\n",
            "Epoch 65, Loss: 0.1232, Accuracy: 95.98%\n",
            "Test Accuracy: 93.30%\n",
            "Checkpoint saved: checkpoints/checkpoint_epoch_65.pth\n"
          ]
        }
      ],
      "source": [
        "train_and_save_checkpoint(model, criterion, optimizer, train_loader, test_loader, epochs=65)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibDXJ4Uycnnf",
        "outputId": "33d017ab-23aa-4a9c-f595-cc53d5ae5b17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AudioClassifier(\n",
              "  (conv_layers): ModuleList(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (batch_norms): ModuleList(\n",
              "    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4-5): 2 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (dropouts): ModuleList(\n",
              "    (0): Dropout(p=0.25, inplace=False)\n",
              "    (1): Dropout(p=0.3, inplace=False)\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3-5): 3 x Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (gmp): AdaptiveMaxPool2d(output_size=1)\n",
              "  (lstm1): LSTM(512, 128, batch_first=True, bidirectional=True)\n",
              "  (lstm2): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
              "  (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (dense2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SeYos9vDli6i"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8x5iAX_73hS",
        "outputId": "ab826062-1e0b-475e-a600-47dcfc74f75b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 98.88%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = evaluate(model, train_loader, device)\n",
        "print(f'Train Accuracy: {train_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enidj15Fy9UI",
        "outputId": "6d75c8b6-65b0-4e53-985f-4f25ef20761b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 64, 348])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tensors[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDAI4oHT8EWp"
      },
      "source": [
        "# Mapping back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UWAmgWbg9LI8"
      },
      "outputs": [],
      "source": [
        "initial_dataset =  load_dataset(\"danavery/urbansound8K\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "bELQH6XV8DPB"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def extract_classes(initial_dataset):\n",
        "  #  initial_dataest is your DatasetDict object\n",
        "  data = initial_dataset['train']\n",
        "  # Creating a dictionary to store unique classID and class pairs\n",
        "  class_dict = defaultdict(set)\n",
        "\n",
        "  # Iterate through the dataset\n",
        "  for example in data:\n",
        "      class_id = example['classID']\n",
        "      class_name = example['class']\n",
        "      class_dict[class_id].add(class_name)\n",
        "\n",
        "  # If you are sure each classID corresponds to only one class,\n",
        "  # you can convert the sets to single values\n",
        "  class_dict = {class_id: next(iter(names)) for class_id, names in class_dict.items()}\n",
        "  return class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "hoD4_ruIzOF-"
      },
      "outputs": [],
      "source": [
        "class_dict = extract_classes(initial_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbp8cngu-Fp0",
        "outputId": "eebc855b-ccc3-4631-bfa0-9047a35728d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{3: 'dog_bark',\n",
              " 2: 'children_playing',\n",
              " 1: 'car_horn',\n",
              " 0: 'air_conditioner',\n",
              " 9: 'street_music',\n",
              " 6: 'gun_shot',\n",
              " 8: 'siren',\n",
              " 5: 'engine_idling',\n",
              " 7: 'jackhammer',\n",
              " 4: 'drilling'}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoI24OT_SKB"
      },
      "source": [
        "# We will create a function to collect 10th batch prediction class names and input tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "TEX-B79l-hN_"
      },
      "outputs": [],
      "source": [
        "def map_predictions_to_class(model, test_loader, device, class_name_mapping):\n",
        "    model.eval()\n",
        "    input_tensors = []\n",
        "    actual_labels_list = []\n",
        "    output_labels = []\n",
        "    output_class_names = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            if i == 10:  # Collect data only for the 10th batch\n",
        "                input_tensors.append(inputs.cpu())\n",
        "                actual_labels_list.extend(labels.cpu().tolist())\n",
        "                output_labels.extend(predicted.cpu().tolist())\n",
        "                output_class_names.extend([class_name_mapping[label.item()] for label in predicted])\n",
        "                break\n",
        "\n",
        "    input_tensors = torch.cat(input_tensors)\n",
        "    output_labels_tensor = torch.tensor(output_labels)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Input Tensors': [tensor.numpy() for tensor in input_tensors],  # Convert tensors to numpy arrays for DataFrame\n",
        "        'Actual Label': actual_labels_list,\n",
        "        'Predicted Label': output_labels,\n",
        "        'Class Name': output_class_names\n",
        "    })\n",
        "\n",
        "    return input_tensors, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "mIrUIASK_jh_"
      },
      "outputs": [],
      "source": [
        "input_tensors, predictions_df = map_predictions_to_class(model, test_loader, device, class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kix3jL1RAArX",
        "outputId": "4cf6a4db-b180-4ee1-b0e1-434c9bf07ca2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-155f5a28-73e6-424e-84a9-2b2823c497ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Tensors</th>\n",
              "      <th>Actual Label</th>\n",
              "      <th>Predicted Label</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[2.2761073, -0.24937595, 0.17752314, 4.68741...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>street_music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[0.26266438, -0.18040122, -0.17845507, -0.18...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>street_music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[-0.3720862, 1.5921863, 0.7920696, 0.3264608...</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>gun_shot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[7.088621, 1.2899628, 1.3319199, 6.9923673, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>air_conditioner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[-0.14231737, 1.7023071, 0.86349, 1.2145898,...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>jackhammer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-155f5a28-73e6-424e-84a9-2b2823c497ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-155f5a28-73e6-424e-84a9-2b2823c497ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-155f5a28-73e6-424e-84a9-2b2823c497ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-387903a1-b688-4ba8-b107-39647422117d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-387903a1-b688-4ba8-b107-39647422117d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-387903a1-b688-4ba8-b107-39647422117d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                       Input Tensors  Actual Label  \\\n",
              "0  [[[2.2761073, -0.24937595, 0.17752314, 4.68741...             9   \n",
              "1  [[[0.26266438, -0.18040122, -0.17845507, -0.18...             9   \n",
              "2  [[[-0.3720862, 1.5921863, 0.7920696, 0.3264608...             6   \n",
              "3  [[[7.088621, 1.2899628, 1.3319199, 6.9923673, ...             0   \n",
              "4  [[[-0.14231737, 1.7023071, 0.86349, 1.2145898,...             7   \n",
              "\n",
              "   Predicted Label       Class Name  \n",
              "0                9     street_music  \n",
              "1                9     street_music  \n",
              "2                6         gun_shot  \n",
              "3                0  air_conditioner  \n",
              "4                7       jackhammer  "
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM0oBxazCv7B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt5SrxndC1zw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s65U_mi1C22r"
      },
      "source": [
        "# Using Pre trained network for this task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2DkNPbJC67l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
